# -*- coding: utf-8 -*-
"""LR_BOW_TFIDF.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1g7pwjr6ZM2f4BM0b4fdY4BjQszGbDWgT

Basic Logistic Regression Classifier to classify sentiments of a review. 

Used Bag of Words to vectorize sentences.

Two types of evaluation:
1. trained and tested on the same data
2. trained and tested based on leave one out concept - trained on (n-1) sources, and tested on the nth term. This leads to lower accuracy than the first approach though.
"""

# https://realpython.com/python-keras-text-classification/
# get the data from here: https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences
# Each review is marked with a score of 0 for a negative sentiment or 1 for a positive sentiment.

# from google.colab import files
# uploaded = files.upload()

import pandas as pd

filepath_dict = {'yelp':   '../Data/yelp_labelled.txt',
                 'amazon': '../Data/amazon_cells_labelled.txt',
                 'imdb':   '../Data/imdb_labelled.txt'}

df_list = []
for source, filepath in filepath_dict.items():
  df = pd.read_csv(filepath, names = ['sentence', 'label'], sep='\t')
  df['source']=source #add another column with the source name
  df_list.append(df)

df = pd.concat(df_list)
print(df)

# illustrating word vocabulary using countVectorizer (example)
sentences = ['John likes ice cream', 'John hates chocolate.']

from sklearn.feature_extraction.text import CountVectorizer

vectorizer = CountVectorizer(min_df=0, lowercase=False)
# It takes the words of each sentence and creates a vocabulary of all the unique words in the sentences. 
# This vocabulary can then be used to create a feature vector of the count of the words:
vectorizer.fit(sentences)
vectorizer.vocabulary_ #this vocabulary serves as an index of each word
# {'John': 0, 'chocolate': 1, 'cream': 2, 'hates': 3, 'ice': 4, 'likes': 5}

# when we transform the two sentences using CountVectorizer, we will get a vector representing the count of each word of the sentence
vectorizer.transform(sentences).toarray()
# array([[1, 0, 1, 0, 1, 1],
#        [1, 1, 0, 1, 0, 0]])

# illustration of Tf-IDF vectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer()

from sklearn.model_selection import train_test_split

df_yelp = df[df['source'] == 'yelp']

sentences = df_yelp['sentence'].values
y = df_yelp['label'].values

sentences_train, sentences_test, y_train, y_test = train_test_split(
   sentences, y, test_size=0.25, random_state=1000)

#use BOW model to vectorize the sentences
vectorizer.fit(sentences_train)

X_train = vectorizer.transform(sentences_train)
X_test  = vectorizer.transform(sentences_test)
X_train

from sklearn.linear_model import LogisticRegression
# logistic regression on yelp data
classifier = LogisticRegression()
classifier.fit(X_train, y_train)
score = classifier.score(X_test, y_test)

print("Accuracy:", score)

# logistic regression for each data set

for source in df['source'].unique():
    df_source = df[df['source'] == source]
    sentences = df_source['sentence'].values
    y = df_source['label'].values

    sentences_train, sentences_test, y_train, y_test = train_test_split(
        sentences, y, test_size=0.25, random_state=1000)

    vectorizer.fit(sentences_train)
    X_train = vectorizer.transform(sentences_train)
    X_test  = vectorizer.transform(sentences_test)

    classifier = LogisticRegression()
    classifier.fit(X_train, y_train)
    score = classifier.score(X_test, y_test)
    print('Accuracy for {} data: {:.4f}'.format(source, score))

# leave one source to test and remaining sources to train the model

for source in df['source'].unique():
  #test data
  df_source_test = df[df['source'] == source]
  # print(df_source_test)
  sentences_test = df_source_test['sentence'].values
  y_test = df_source_test['label'].values
  

  #train data - combine the remaining sources as one
  df_source_train = df[df['source'] != source]
  # print(df_source_train)
  sentences_train = df_source_train['sentence'].values
  y_train = df_source_train['label'].values

  vectorizer.fit(sentences_train)
  X_train = vectorizer.transform(sentences_train)
  X_test  = vectorizer.transform(sentences_test)

  classifier = LogisticRegression()
  classifier.fit(X_train, y_train)
  score = classifier.score(X_test, y_test)
  print('Accuracy for {} data: {:.4f}'.format(source, score))